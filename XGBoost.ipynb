{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARAVIND NACHIAPPAN\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\Users\\ARAVIND NACHIAPPAN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\ARAVIND NACHIAPPAN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\ARAVIND NACHIAPPAN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\ARAVIND NACHIAPPAN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\ARAVIND NACHIAPPAN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\ARAVIND NACHIAPPAN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"train_ctrUa4K.csv\")\n",
    "for column in ('Gender','Married','Dependents','Self_Employed'):\n",
    "    data[column].fillna(data[column].mode()[0],inplace=True)\n",
    "for column in ('LoanAmount','Loan_Amount_Term','Credit_History'):\n",
    "    data[column].fillna(data[column].mean(),inplace=True)\n",
    "for variable in ('Gender','Married','Dependents','Education','Self_Employed','Property_Area'):\n",
    "    data[variable].fillna(\"Missing\",inplace=True)\n",
    "    dummies=pd.get_dummies(data[variable],prefix=variable)\n",
    "    data=pd.concat([data,dummies],axis=1)\n",
    "    data.drop([variable],axis=1,inplace=True)\n",
    "data['Loan_Status']=data.Loan_Status.map({'Y':0,'N':1})\n",
    "Y=data['Loan_Status']\n",
    "data.drop(['Loan_Status'],axis=1,inplace=True)\n",
    "X=data[data.iloc[:,1:23].columns]\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,random_state=100,test_size=0.2)\n",
    "scaler=StandardScaler()\n",
    "scaled_X_train=scaler.fit_transform(X_train)\n",
    "scaled_X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.001, 'max_depth': 1, 'max_features': 1, 'n_estimators': 150}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xg_param(X, y, nfolds):\n",
    "    n_estimators=[150,200,500,1000,1500,2000]\n",
    "    max_features=[1,2,3]\n",
    "    max_depth=[1,2,3,4,5,6,7,8,9,10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'n_estimators': n_estimators,'max_features':max_features,'max_depth':max_depth,'gamma':gammas}\n",
    "    grid_search_xg = GridSearchCV(XGBClassifier(learning_rate= 0.05), param_grid, cv=nfolds)\n",
    "    grid_search_xg.fit(X,y)\n",
    "    return grid_search_xg.best_params_\n",
    "xg_param(scaled_X_train,Y_train,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall for XGBoost model: 0.3958333333333333\n",
      "Precision for XGBoost model: 0.8636363636363636\n",
      "Accuracy for XGBoost model: 0.7398373983739838\n",
      "F-score for XGBoost model: 0.5428571428571428\n",
      "Log-loss for XGBoost model: 8.985717426255547\n"
     ]
    }
   ],
   "source": [
    "XG_model=XGBClassifier(n_estimators=150, learning_rate = 0.05, max_features=1, max_depth = 1,gamma=0.001)\n",
    "XG_model.fit(scaled_X_train,Y_train)\n",
    "XG_pred=XG_model.predict(scaled_X_test)\n",
    "print(\"Recall for XGBoost model:\",metrics.recall_score(Y_test,XG_pred))\n",
    "print(\"Precision for XGBoost model:\",metrics.precision_score(Y_test,XG_pred))\n",
    "print(\"Accuracy for XGBoost model:\",metrics.accuracy_score(Y_test,XG_pred))\n",
    "print(\"F-score for XGBoost model:\",metrics.f1_score(Y_test,XG_pred))\n",
    "print(\"Log-loss for XGBoost model:\",metrics.log_loss(Y_test,XG_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
